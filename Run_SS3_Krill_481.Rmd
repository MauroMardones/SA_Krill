---
<<<<<<< HEAD
title: "Implicit spatial model to krill Dynamic Population in Antarctic Peninsula, 48-1 SubArea. SS3 aplications"
subtitle: "Working Paper to be submitted in CCAMLR WG-FSA 2024"
author:
  - Mardones Mauricio^[Instituo de Fomento Pesquero, mardones.mauricio@gmail.com]
  - César Cárdenas^[Instituto Antártico Chileno]
date:  "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: SA_krill.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
always_allow_html: yes
output:
  pdf_document
---

```{=tex}
\fontsize{12}{16}
\selectfont{}
```
\newpage

```{=latex}
\setcounter{tocdepth}{3}
\tableofcontents
```
\newpage

```{r setup1, echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE,
                      eval=FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.pos = "H",
                      dev = 'jpeg',
                      dpi = 300,
                      tidy.opts=list(width.cutoff=80), 
                      tidy=TRUE)
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```

# ABSTRACT 





The stock assessment model for *Euphausia superba* (hereafter krill) in the Antarctic Peninsula, operating within a spatial-temporal and ecosystemic framework, highlights the importance of incorporating spatial heterogeneity. The spatial heterogeneity, such as variations in oceanographic conditions and habitat suitability across different regions, is likely to outperform a population dynamics of krill. By accounting for spatial heterogeneity, a integrated stock assessment model can better capture localized dynamics and interactions, leading to more accurate predictions of krill population dynamics. This nuanced approach allows for a more refined understanding of diferente zones shape krill abundance, fishing mortalyty and recruitment patterns across the Antarctic Peninsula. Consequently, by acknowledging and integrating spatial heterogeneity, the stock assessment model can provide more robust insights into the ecological dynamics of krill populations and improve CCAMLR fishery management and conservation strategies in this region.

*Keywords: Krill populations, dynamic population, stock assessment, SS3, spatial implicit, management, CCAMLR.*



# INTRODUCTION




# METHODOLOGY

## Conceptual Model 

## Phases in model construction

The process of modeling and statistical analysis of a database can be structured according to the following guidelines:

- Contextualization of the problem. Definition of objectives and variables.
- Experiment design and data collection.
- Recording and preliminary processing of available information.
- Graphical inspection and trend identification.
- Consideration of distributional and relational hypotheses. Proposal of modeling.
- Model adjustment. Comparison and selection of the best model.
- Diagnosis and validation of the adjusted model.
- Assessment of the predictive capacity of the model and prediction.
- Interpretation and conclusions.

## Scenarios

In Table 1 we have ten scenarios to test different option in modeling about main consideration in assessment of krill population.

| Scenario | Description                                      |
|:---------:|:-------------------------------------------------|
|    s01     | Fishery, Predator, Survey, Environmental data agreggate (Whole 48.1) |
|    s1     | Fishery data (Length, Index, Catch) by strata  and Predator and Env data      |
|    s2    | Fishery and Survey (AMLR) data Length, Index, Catch by strata and Predator and Env data |
|    s3     | Same "s2" Without S-R relation         |
|    s4     | Same "s2" Ricker S-R relation estimated          |
|    s5     | Same "s2" BH S-R relation weak (0.9 steepness)     |
|    s6     | Same "s2" BH S-R relation strong (0.6 steepness)     |
|    s7     | Same "s2" BH S-R relation mid-strong (0.65 steepness) estimated     |

## Statistical model (SS3)

The stock assesment model was configured using Stock Synthesis (SS3 hereafter)[SS3](https://vlab.noaa.gov/web/stock-synthesis) [@Methot2013] with the most updated version (V.3.30.21). SS3 is a structured age and size stock evaluation model, in the class of models called *"Integrated stock evaluation analysis model"*. SS3 has a stock population sub-model that simulates growth, maturity, fecundity, recruitment, movement, and mortality processes, and observation sub-models and expected values for different types of data. The model is coded in `C++` with estimation parameters enabled by automatic differentiation (ADMB) [@Fournier2012; @Methot2013]. The analysis of results and outputs uses R tools and the graphical interface of the *r4ss* library [@Taylor2019; @Winker2023].

## Model setup
=======
title: "Run_SS3_Krill_481"
author: "Mauricio Mardones I."
date: '2022-06-15'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5

```{r message=FALSE}
# install.packages("devtools")
# devtools::install_github("r4ss/r4ss", ref="development")
<<<<<<< HEAD
# install.packages("caTools")
# library("caTools")
=======
# 
# install.packages("caTools")
# library("caTools")
# 
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
# install.packages("r4ss")
library(r4ss)
library(here)
#remotes::install_github("PIFSCstockassessments/ss3diags")
library(ss3diags)
```


```{r message=FALSE, warning=FALSE}
<<<<<<< HEAD
dir01 <- here("s01") # agreggate data (no spatial diferences)
dir1<-here("s1") # Data strata flishery
dir2<-here("s2") # Same 9 with areas (SubStrata) as fleet. Dif size comoposition and dif CPUE and dif survey length and biomass data by strata
dir3<-here("s3") # whitout S-R
dir4<-here("s4") # 
dir5<-here("s5") # whitout S-R
dir6<-here("s6") # whitout S-R
dir7<-here("s7") # whitout S-R
```


```{r eval=FALSE, message=F, include=FALSE}
# Lista de directorios para correro tordos juntos
directorios <- c("s01", 
                 "s1", 
                 "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7")  # Agrega aquí todos los nombres de las carpetas que deseas procesar

# Bucle para ejecutar el código en cada directorio
for (dir in directorios) {
  r4ss::run(
    dir = dir,
    exe = "ss_osx",
    skipfinished = FALSE,
    show_in_console = TRUE
  )
}

#OR with rby separate

#shell(cmd="ss") # run SS to windows
# or 
#system('./ss_osx') # to mac

# r4ss::run(
#   dir = dir1,
#   exe = "ss_osx",
#   skipfinished = FALSE, # TRUE will skip running if Report.sso present
#   show_in_console = TRUE # change to true to watch the output go past
# )
```


```{r message=F, include=FALSE}
#s01
base.model01 <- SS_output(dir=dir01,
                        covar=T,
                        forecast=T)
#s1
base.model1 <- SS_output(dir=dir1,
                        covar=T,
                        forecast=T)
#s2
base.model2 <- SS_output(dir=dir2,
                        covar=T,
                        forecast=T)
#s3
base.model3 <- SS_output(dir=dir3,
                        covar=T,
                        forecast=T)
#s4
base.model4 <- SS_output(dir=dir4,
                        covar=T,
                        forecast=T)

#s7
base.model7 <- SS_output(dir=dir7,
                        covar=T,
                        forecast=T)


=======
dir1<-here("~/DOCAS/SA_Krill/s1")
dir2<-here("~/DOCAS/SA_Krill/s2")
dir3<-here("~/DOCAS/SA_Krill/s3_longer")
dir4<-here("~/DOCAS/SA_Krill/s3")
```


```{r}
#shell(cmd="ss") # run SS para windows
# aqui debo cambiar el setwd() para correr el modelo

r4ss::run_SS_models(dirvec = dir4, model = './ss_osx', 
                    skipfinished = FALSE) 
```



```{r}
dir4<-here("s3")
base.model <- SS_output(dir=dir4,covar=F,forecast=F)
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
```

Saco los outputs en html

<<<<<<< HEAD
```{r eval=FALSE,  message=F, include=FALSE}
SS_plots(base.model7, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)
=======
```{r eval=FALSE}
SS_plots(base.model, uncertainty=T,datplot = F, png=T, aalresids = F,btarg=0.75, minbthresh=0.25, forecast=F)
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
```



Data disponible para este escenario. Espinel es la serie mas consistente del conjunto de datos.

```{r}
<<<<<<< HEAD
SSplotData(base.model, subplots = 2)


=======
SSplotData(base.model, subplot = 2, 
           fleetnames = c("Fishery", "Survey"),
           fleetcol = c(4,6))
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
```

Respecto a los valores y parametros biologicos modelados, los siguientes graficos identifican los estimadores puntuales del recurso

```{r}
<<<<<<< HEAD
SSplotSelex(base.model)
=======
SSplotBiology(base.model, subplots =1, labels = c("Length (cm)", "Age (yr)", "Maturity", "Mean weight (kg) in last year",
    "Spawning output", "Length (cm, beginning of the year)", "Natural mortality",
    "Female weight (kg)", "Female length (cm)", "Fecundity", "Default fecundity label",
    "Year", "Hermaphroditism transition rate", "Fraction females by age at equilibrium"),
 )
>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
```

aporte de las cohortes por año para las capturas.
```{r}
SSplotCohortCatch(base.model, subplots = 1)
```

\quad

AJuste de tallas por flota
```{r}
SSplotComps(base.model, subplots = 1)
```

Otros plots
```{r}
SSplotDynamicB0(base.model, uncertainty = F)
#SSplotSPR(base.model3)
SSplotPars(base.model)

```

Salida de las biomasas con las dos flotas


```{r}
<<<<<<< HEAD
SSplotTimeseries(base.model7, subplot = 1)
```


```{r}
SSplotTimeseries(base.model,
  subplot=1,
  add = FALSE,
  forecastplot = FALSE,
  uncertainty = TRUE,
  bioscale = 1,
  minyr = -Inf,
  maxyr = Inf,
  plot = TRUE,
  print = FALSE,
  plotdir = "default",
  verbose = TRUE,
  btarg = "default",
  minbthresh = "default",
  xlab = "Year",
  labels = NULL,
  pwidth = 6.5,
  pheight = 5,
  punits = "in",
  res = 300,
  ptsize = 10,
  cex.main = 1,
  mainTitle = FALSE,
  mar = NULL
)
```

# Diagnosis Base Model (Jabba)


step to do a good practice in diagnosis is;
- 1. Convergence. Final convergence criteria is 1.0e-04
- 2. Residual 
- 3. Restrospective analysis
- 4. Likelihood profile



## Residual

```{r}
SSplotRunstest(base.model4, 
               subplots = "cpue",
               add=T)
SSplotRunstest(base.model4, 
               subplots = "len",
               add=T)
```


```{r}
SSplotJABBAres(base.model,
               subplots = "cpue",
               add=T)
SSplotJABBAres(base.model,
               subplots = "len",
               add=T)
```



### Predator fleet with RW

Random Walk (RW) refers to a mathematical model that describes a stochastic process in which a variable changes randomly over time, without a clear trend or pattern.

Specifically, a random walk can be used as a Bayesian estimation technique to infer the posterior distribution of an unknown parameter. In this approach, it is assumed that the prior distribution of the parameter is a normal distribution with mean zero and a known variance, and that the parameter value at each time step follows a random walk process. Based on the observed data and the prior distribution, the posterior distribution of the parameter can be calculated using Bayesian inference.

Random walk is a useful tool for parameter estimation in dynamic models, as it allows for modeling uncertainty and variability in the parameter's evolution over time. However, it is important to note that the random walk assumes that the changes in the parameter are random and without a clear trend, which may not be appropriate in all cases.

# Retrospectivo

Los análisis retrospectivo, dan cuenta de diferencias de estimación (sub - sobreestimación) en los patrones entre modelos evaluados. 

```{r eval=FALSE}
retro(dir=dir7, oldsubdir="", 
      newsubdir="Retrospective", 
      years= 0:-5,
      exe="ss_osx",
      extras = "-nox", 
      skipfinished = F)
```


```{r}
retroModels <- SSgetoutput(dirvec=file.path(dir01,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary <- SSsummarize(retroModels)
```


```{r}
#save(retroSummary, retroModels, file="retro5.Rdata")

retro01 <- SSplotRetro(retroSummary,
            add=T,
            forecast = F,
            legend = F,
            verbose=F)
retro2 <- SSplotRetro(retroSummary,
            add=T,
            forecast = F,
            legend = F,
            verbose=F)
retro1 <- SSplotRetro(retroSummary,
            add=T,
            forecast = F,
            legend = F,
            verbose=F)

retro7 <- SSplotRetro(retroSummary,
            add=T,
            forecast = F,
            legend = F,
            verbose=F,
            legendlabels="default")
```
## Hindcast Cross-Validation and prediction skill

Implementing the Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis requires the same model outputs generated by `r4ss:SS_doRetro()`. As a robust measure of prediction skill, we implemented the mean absolute scaled error (MASE). In brief, the MASE score scales the mean absolute. Regarding (A MASE score > 1 indicates that the average model forecasts are worse than a random walk. Conversely, a MASE score of 0.5 indicates that the model forecasts twice as
accurately as a naïve baseline prediction; thus, the model has prediction skill.



```{r}
hci = SSplotHCxval(retroSummary, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```
# Kobe

```{r}
mvln = SSdeltaMVLN(base.model01,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)


```


```{r}
retroModels <- SSgetoutput(dirvec=file.path(mydir, "Retrospective",paste("retro",0:-5, sep="")))
retroSummary <- SSsummarize(retroModels)
endyrvec <- retroSummary$endyrs + 0:-5
save(retroSummary, retroModels, file="retro5.Rdata")
# Step 1. Identify restrospective period
# e.g., for end.yr.vec   <- c(2015,2014,2013,2012,2011,2010)
start.retro <- 0    #end year of model e.g., 2015
end.retro   <- 5    #number of years for retrospective e.g., 2014,2013,2012,2011,2010

# Step 2. Identify the base directory
dirname.base <- here("SA_Krill")
dirname.base

# Step 3. Identify the directory where a completed model run is located
dirname.completed.model.run <- here("s9")
dirname.completed.model.run

# Step 4. Create a subdirectory for the Retrospectives
dirname.Retrospective <- here("Ejercicios","Retrospectivo") 
dir.create(path=dirname.Retrospective, showWarnings = TRUE, recursive = TRUE)
setwd(dirname.Retrospective)
getwd()

# Step 5. Create a subdirectory for the Plots
dirname.plots <- paste0(dirname.Retrospective,"/plots_retro")
dir.create(dirname.plots)

# 7. Copiar los archivos necesarios de "Reference_run" al directorio "Perfil_Verosimilitud" ----

copy_SS_inputs(dir.old = dirname.completed.model.run, 
               dir.new =  dirname.Retrospective,
               copy_exe = TRUE,
               verbose = FALSE)


# #----------------- copy model run files ----------------------------------------
# file.copy(paste(dirname.completed.model.run,       "starter.ss_new", sep="/"),
#           paste(dirname.Retrospective, "starter.ss", sep="/"))
# 
# file.copy(paste(dirname.completed.model.run,       "control.ss_new", sep="/"),
#           paste(dirname.Retrospective, "CONTROL.SS", sep="/"))
# 
# file.copy(paste(dirname.completed.model.run,       "data.ss", sep="/"),
#           paste(dirname.Retrospective, "DATA.SS", sep="/"))	
# 
# file.copy(paste(dirname.completed.model.run,       "forecast.ss", sep="/"),
#           paste(dirname.Retrospective, "forecast.ss", sep="/"))
# 
# file.copy(paste(dirname.completed.model.run,       "ss_win.exe", sep="/"),
#           paste(dirname.Retrospective, "SS.exe", sep="/"))

# # Required for assessments with wtatage.ss files
# file.copy(paste(dirname.completed.model.run,       "wtatage.ss", sep="/"),
#           paste(dirname.Retrospective, "wtatage.ss", sep="/"))

#------------Make Changes to the Starter.ss file (DC Example) ------------------------------- 
starter <- readLines(paste(dirname.Retrospective, "/starter.ss", sep=""))

# 1) Starter File changes to speed up model runs
# Run Display Detail
#[8] "2 # run display detail (0,1,2)" 
linen <- grep("# run display detail", starter)
starter[linen] <- paste0( 1 , " # run display detail (0,1,2)" )
write(starter, paste(dirname.Retrospective, "starter.ss", sep="/"))

#------------ r4SS retrospective calculations------------------------------- 

# Step 6. Run the retrospective analyses with r4SS function "SS_doRetro"
retro(masterdir=dirname.Retrospective,
           oldsubdir="", 
           newsubdir="retrospectives",
           years=start.retro:-end.retro)

# Step 7. Read "SS_doRetro" output
retroModels <- SSgetoutput(dirvec=file.path(dirname.Retrospective, "retrospectives",paste("retro",start.retro:-end.retro,sep="")))

# Step 8. Summarize "SS_doRetro" output
retroSummary <- SSsummarize(retroModels)

sspar(mfrow=c(1,2),plot.cex=0.8)
rb = SSplotRetro(retroSummary,add=T,forecast = F,legend = F,verbose=F)
rf = SSplotRetro(retroSummary,add=T,subplots="F", ylim=c(0,0.4),
                 forecast = F,legendloc="topleft",legendcex = 0.8,verbose=F)

sspar(mfrow = c(2, 1), plot.cex = 0.8)

SSplotRetro(retroSummary, 
            add = T, 
            forecast = T, 
            legend = F, 
            verbose = F, 
            xmin = 1970)
SSplotRetro(retroSummary, 
            add = T, 
            subplots = "F", 
            ylim = c(0, 0.06), 
            forecast = T,
            legendloc = "topleft", 
            legendcex = 0.8, 
            verbose = F, 
            xmin = 1970)


SShcbias(retroSummary,quant="SSB",verbose=F)
SShcbias(retroSummary,quant="F",verbose=F)
```



# Verosimilitud


```{r}
# 1. Identificar el directorio donde se encuentra el modelo base ----
dirname.model.run <- here("s10")

# 2. Crear un nuevo directorio para el "Perfil_Verosimilitud"  


dirname.R0.profile <- here("Ejercicios","Perfil_Verosimilitud")
dir.create(path=dirname.R0.profile, showWarnings = TRUE, recursive = TRUE)


# 3. Crear un subdirectorio llamado "plots_Verosimilitud" ----


plotdir=paste0(dirname.R0.profile, "/plots_Verosimilitud")
dir.create(path=plotdir, showWarnings = TRUE, recursive = TRUE)




# 4. Crear un subdirectorio llamado "simple" ----

reference.dir <- paste0(dirname.R0.profile,'/simple') 
dir.create(path=reference.dir, showWarnings = TRUE, recursive = TRUE)




# 5. Copiar el resultado del modelo base completo en este directorio ----

file.copy(Sys.glob(paste(dirname.model.run, "*.*", sep="/"),
                   dirmark = FALSE),
                    reference.dir)


# 6. Leer la salida del modelo base ----


Base <- SS_output(dir=reference.dir,covar=T)




# 7. Copiar los archivos necesarios de "simple" al directorio "Perfil_Verosimilitud" ----

copy_SS_inputs(dir.old = reference.dir, 
               dir.new =  dirname.R0.profile,
               copy_exe = TRUE,
               verbose = FALSE)




# 8. Leer los archivos del modelo ----

inputs <- r4ss::SS_read(dir = dirname.R0.profile)



# 9. Editar el archivo control la fase de estimación recdev ----

inputs$ctl$recdev_phase <- 1




# 10. Editar el archivo starter para leer los valores de inicio ----


inputs$start$init_values_src <- 0




# 11. Vector de valores para el perfil ----


R0.vec <- seq(7,11,0.5)  
Nprof.R0 <- length(R0.vec)




# 12. Cambiar el nombre del archivo control en el archivo starter.ss ----

inputs$start$ctlfile <- "control_modified.ss" 




# 13. Incluir prior_like para parámetros no estimados ----

inputs$start$prior_like <- 1                                 




# 14. Escribir los modelos modificados ----

r4ss::SS_write(inputs, dir = dirname.R0.profile, overwrite = TRUE)




# 15. Ejecutar la función profile() ----

?SS_profile()
profile <- profile(dir="dir10", # directory
                      model="ss_osx",
                      oldctlfile ="control.ss",
                      newctlfile="control_modified.ss",
                      string="SR_LN(R0)",
                      profilevec=R0.vec)




# 16. Leer los archivos de salida ----
# (con nombres como Report1.sso, Report2.sso, etc.)
prof.R0.models <- SSgetoutput(dirvec=dirname.R0.profile, 
                              keyvec=1:Nprof.R0, 
                              getcovar = FALSE) 

# 17. Resumir las salidas con la función SSsummarize()  ----
prof.R0.summary <- SSsummarize(prof.R0.models)

# 18. Identificar los componentes de Verosimilitud ----
mainlike_components         <- c('TOTAL',"Survey", 'Length_comp',"Age_comp",'Size_at_age','Recruitment') 
mainlike_components_labels  <- c('Total likelihood','Index likelihood','Length likelihood',"Age likelihood",'Size_at_age likelihood','Recruitment likelihood') 

# 19. Funciones para generar plots de perfil de verosimilitud ----
### SSplotProfile() ----
png(file.path(plotdir,"R0_profile_plot.png"),width=7,height=4.5,res=300,units='in')
par(mar=c(5,4,1,1))

SSplotProfile(prof.R0.summary,           # summary object
              profile.string = "R0",     # substring of profile parameter
              profile.label=expression(log(italic(R)[0])), ymax=150,minfraction = 0.001,
              pheight=4.5, 
              print=FALSE, 
              plotdir=plotdir, 
              components = mainlike_components, 
              component.labels = mainlike_components_labels,
              add_cutoff = TRUE,
              cutoff_prob = 0.95)

Baseval <- round(Base$parameters$Value[grep("R0",Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()


### SSplotComparisons() ----
# Comparación de series de tiempo 
labs <- paste("SR_Ln(R0) = ",R0.vec)
labs[which(round(R0.vec,2)==Baseval)] <- paste("SR_Ln(R0) = ",Baseval,"(Base model)")

SSplotComparisons(prof.R0.summary,
                  legendlabels=labs,
                  pheight=4.5,png=TRUE,
                  plotdir=plotdir,
                  legendloc='bottomleft')

### PinerPlot() ----
#### R0_profile_plot_Length_like ----
png(file.path(plotdir,"R0_profile_plot_Length_like.png"),width=7,height=4.5,res=300,units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, 
          profile.string = "R0", 
          component = "Length_like",
          main = "Changes in length-composition likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95)
Baseval <- round(Base$parameters$Value[grep("SR_LN",
                                      Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,
     label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
#### R0_profile_plot_Survey_like ----
png(file.path(plotdir,"R0_profile_plot_Survey_like.png"),width=7,height=4.5,res=300,units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, profile.string = "R0", component = "Surv_like",main = "Changes in Index likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95, legendloc="topleft")
Baseval <- round(Base$parameters$Value[grep("SR_LN",Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
```

# COMPARACION DE MODELOS con distinto desembarque

```{r}
#PLOT labels, name of each model run
legend.labels <- c( 
                  "s1",
                 "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7")

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL,
                       dirvec = c(
                                  dir1,
                                  dir2,
                                  dir3,
                                  dir4,
                                  dir5,
                                  dir6,
                                  dir7),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)

SSplotComparisons(summaryoutput,
                  legendlabels = c("s1","s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                 labels = c("Year", 
                            "Spawning biomass (t)",
                            "Relative spawning biomass", 
                            "Age-0 recruits (1,000s)",
                            "Recruitment deviations", 
                            "Index", "Log index", 
                            "1 - SPR", 
                            "Density",
                            "Management target", 
                            "Minimum stock size threshold",
                            "Spawning output",
                            "Harvest rate"))
```


```{r}
SStableComparisons(summaryoutput,
                   likenames = c("TOTAL", 
                                 "Survey", 
                                 "Length_comp",
                                 "Age_comp", 
                                 "priors",
                                 "Size_at_age"), 
                   names = c("Recr_Virgin",
                             "R0", 
                             "steep",
                             "NatM",
                             "L_at_Amax", 
                             "VonBert_K", 
                             "SSB_Virg", 
                             "Bratio_2017",
                             "SPRratio_2016"),
                   digits = NULL,
                   modelnames = c("s1","s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                   csv = FALSE,
                   csvdir =~"/DOCAS/SA_Krill",
                   csvfile = "parameter_comparison_table.csv",
                 verbose = TRUE,
                   mcmc = FALSE)
=======
SSplotTimeseries(base.model, subplot = 1)
```



```{r}
#########################################################################
#COMPARACION DE MODELOS con distinto desembarque
#########################################################################


#PLOT labels, name of each model run
legend.labels <- c('SSdir1','SSdir2','SSdir3')

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL, dirvec = c(SSdir1,SSdir2,SSdir3),	getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)

SSplotComparisons(summaryoutput, subplots = 1:20, plot = TRUE,
                  print = T, endyrvec = "default", indexfleets = NULL, indexUncertainty = FALSE,
                  indexQlabel = TRUE, indexQdigits = 4, indexSEvec = "default",
                  indexPlotEach = FALSE, labels = c("Year", "Spawning biomass (t)",
                                                    "Relative spawning biomass", "Age-0 recruits (1,000s)",
                                                    "Recruitment deviations", "Index", "Log index", "1 - SPR", "Density",
                                                    "Management target", "Minimum stock size threshold", "Spawning output",
                                                    "Harvest rate"), col = NULL, shadecol = NULL, pch = NULL,
                  lty = 1, lwd = 2, spacepoints = 10, staggerpoints = 1,
                  initpoint = 0, tickEndYr = TRUE, shadeForecast = TRUE,
                  xlim = "default", ylimAdj = 1, xaxs = "r", yaxs = "r",
                  type = "o", uncertainty = TRUE, shadealpha = 0.1, legend = TRUE,
                  legendlabels = "default", legendloc = "topright",
                  legendorder = "default", legendncol = 1, sprtarg = NULL,
                  btarg = NULL, minbthresh = NULL, pwidth = 6.5, pheight = 5,
                  punits = "in", res = 300, ptsize = 10, cex.main = 1,
                  plotdir = "C:\\Users\\mauricio.mardones\\Documents\\IFOP\\Loco_Assessment_AMERB\\SA_Loco", filenameprefix = "", densitynames = c("SSB_Virgin",
                                                                                                                     "R0"), densityxlabs = "default", densityscalex = 1,
                  densityscaley = 1, densityadjust = 1, densitysymbols = TRUE,
                  densitytails = TRUE, densitymiddle = FALSE, densitylwd = 1,
                  fix0 = TRUE, new = TRUE, add = FALSE, par = list(mar = c(5, 4, 1,
                                                                           1) + 0.1), verbose = TRUE, mcmcVec = FALSE,
                  show_equilibrium = TRUE)


SStableComparisons(summaryoutput,
                   likenames = c("TOTAL", "Survey", "Length_comp", "Age_comp", "priors",
                                 "Size_at_age"), names = c("Recr_Virgin", "R0", "steep", "NatM",
                                                           "L_at_Amax", "VonBert_K", "SSB_Virg", "Bratio_2017", "SPRratio_2016"),
                   digits = NULL, modelnames = "default", csv = FALSE,
                   csvdir = "C:\\Users\\mauricio.mardones\\Documents\\IFOP\\Loco_Assessment_AMERB\\SA_Loco",
                   csvfile = "parameter_comparison_table.csv", verbose = TRUE,
                   mcmc = FALSE)
```

# Analisis retrospectivo

```{r}

#do retrospective model runs
SS_doRetro('C:\\SAFS\\SS\\Modelos_Seattle\\Anchoveta\\month\\5', '', newsubdir = "retrospectives",
           subdirstart = "retro", years = 0:-5, overwrite = TRUE, exefile = "ss",
           extras = "-nox -nohess", intern = FALSE, CallType = "system",
           RemoveBlocks = FALSE)
retroModels <- SSgetoutput(dirvec=file.path('C:\\SAFS\\SS\\Modelos_Seattle\\Anchoveta\\month\\5', "retrospectives",paste("retro",0:-5,sep="")))
retroSummary <- SSsummarize(retroModels)
endyrvec <- retroSummary$endyrs + 0:-5
SSplotComparisons(retroSummary, endyrvec=endyrvec, legendlabels=paste("Data",0:-5,"years"),
                  plotdir='C:\\SAFS\\SS\\Modelos_Seattle\\Anchoveta\\month\\',plot=TRUE,print=T)
TableCompare <- SStableComparisons(retroSummary,likenames=like, names=names, 
                                   modelnames=c('B','-1','-2','-3','-4','-5'), csv=TRUE, csvfile="RetroRuns.csv",verbose=FALSE)
##############################################################################################



>>>>>>> b9427ff069cad766960c2f0138ac1537b2c9aac5
```

