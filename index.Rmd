---
title: "Implicit spatial model to krill Dynamic Population in Antarctic Peninsula, 48-1 SubArea. SS3 aplications"
subtitle: "Working Paper to be submitted in a CCAMLR EMM-WG 2024"
author: "Mardones, M; Cárdenas, C., Krüger, L., Santa Cruz, F."
date:  "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: SA_krill.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
output:
  html_document:
    keep_md: true
    toc: true
    toc_deep: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: cosmo
    fontsize: 0.9em
    linestretch: 1.7
    html-math-method: katex
    self-contained: true
    code-tools: true
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup1, echo=FALSE}
rm(list = ls())
set.seed(999)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.pos = "H",
                      dev = 'jpeg',
                      dpi = 300,
                      tidy.opts=list(width.cutoff=50), 
                      tidy=TRUE)
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```


```{r message=FALSE, eval=TRUE}
# install.packages("devtools")
# devtools::install_github("r4ss/r4ss", ref="development")
# install.packages("caTools")
# library("caTools")
# install.packages("r4ss")
library(r4ss)
library(here)
#remotes::install_github("PIFSCstockassessments/ss3diags")
library(ss3diags)
library(kableExtra)
library(doParallel) # facilita la ejecución paralela en R
detectCores()
registerDoParallel(8)
library(ggpubr)
library(tibble)
library(openxlsx)
```


```{r message=FALSE, warning=FALSE}
dir01 <- here("s01") # agreggate data (no spatial diferences)
dir1<-here("s1") # Data strata flishery
dir2<-here("s2") # Same 9 with areas (SubStrata) as fleet. Dif size comoposition and dif CPUE and dif survey length and biomass data by strata
dir3<-here("s3") # whitout S-R
dir4<-here("s4") # 
dir5<-here("s5") # whitout S-R
dir6<-here("s6") # whitout S-R
dir7<-here("s7") # whitout S-R
```

# OVERVIEW


In a simple way, the core of Stock Synthesis is its population dynamics model, which represents the dynamics of krill populations over time. This model incorporates key biological, environmental and predator data sources. The model is typically formulated using mathematical equations that describe how these parameters interact to determine the abundance and distribution of krill in the study area.

## Statistical model (SS3)

Stock Synthesis v.3.30.21 is a widely used software tool for assessing fish and invertebrate populations, including krill (Euphausia superba) in the Antarctic Peninsula region. The methodology employed by Stock Synthesis involves a comprehensive and integrated approach, utilizing various data sources and modeling techniques to estimate the main population variables of krill in WAP. 

The stock assesment model was configured using Stock Synthesis (SS3 hereafter)[SS3](https://vlab.noaa.gov/web/stock-synthesis) [@Methot2013; @methot2020stock] with the most updated version (V.3.30.21). SS3 is a structured age and size stock evaluation model, in the class of models called *"Integrated stock evaluation analysis model"*. SS3 has a stock population sub-model that simulates growth, maturity, fecundity, recruitment, movement, and mortality processes, and observation sub-models and expected values for different types of data. The model is coded in `C++` with estimation parameters enabled by automatic differentiation (ADMB) [@Fournier2012; @Methot2013]. The analysis of results and outputs uses R tools and the graphical interface of the *r4ss* and *ss3diags* library [@Taylor2019; @Winker2023].

By integrating data from multiple sources and considering spatial heterogeneity, the assessment methodology using Stock Synthesis v.3.30.21 provides a robust framework for evaluating the status of krill populations in the Antarctic Peninsula region. This information is essential for supporting management decisions aimed at ensuring the sustainable use of krill resources in this ecologically sensitive area.

## Parametres 

read files

```{r}
# leo archivos para plotear y hacer tablas
start2 <- SS_readstarter(file = file.path(dir2,
                                          "starter.ss"),
                              verbose = FALSE)
# note the data and control file names can vary, so are determined from the 
# starter file.
dat2 <- SS_readdat(file = file.path(dir2, start2$datfile),
                        verbose = FALSE)
# Read in ctl file. Note that the data fileR object is needed so that SS_readctl
# assumes the correct data structure
ctl2 <-  r4ss::SS_readctl(file = file.path(dir2,
                                    start2$ctlfil),
                        verbose = FALSE,
                        use_datlist = TRUE, 
                   datlist = dat2)
fore2 <- r4ss::SS_readforecast(file = file.path(dir2, 
                                                "forecast.ss"),
                              verbose = FALSE)
# can also read in wtatage.ss for an empirical wt at age model using
# r4ss::SS_readwtatage()
```

```{r}
parbio<-ctl2$MG_parms[1:10,c(1:3,7)]
 row.names( parbio)<-c("Nat M",
                       "Lmin", 
                       "Lmax",
                       "VonBert K",
                       "CV young",
                       "CV old", 
                       "Wt a", 
                       "Wt b",
                       "L50%", 
                       "Mat slope")

 SRpar<-ctl2$SR_parms[1:5,c(1:3,7)]
 Qpar<-ctl2$Q_parms[1:2,c(1:3,7)]
 Selpar<-ctl2$size_selex_parms[1:22,c(1:3,7)]
 parInit<-rbind(parbio,SRpar,Qpar,Selpar)
 
wb <- createWorkbook()

addWorksheet(wb, "parameters")
writeData(wb, "parameters", parInit)

# Guardar el workbook
saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)

```


```{r}
parInit %>%
  kbl(booktabs = T,
      format = "latex",
      position="ht!",
    caption = "\\label{Tab1}Input parameters for the initial SS3 model of krill. Each parameter line contains a minimum value (LO), maximum value (HI), and initial value (INIT). If the phase (PHASE) for the parameter is negative, the parameter is fixed as input") %>%
  kable_paper("hover", 
              full_width = F)%>%
  kable_styling(latex_options = c("striped",
                                  "condensed"),
                full_width = FALSE,
                font_size=9)%>% 
  pack_rows(index = c("Mortalidad natural" = 1,
                        "Crecimiento"= 5,
                        "Relación longitud-peso" = 2,
                        "Ojiva de madurez"=2,
                        "Relación stock-recluta"=5,
                        "Capturabilidad"=2,
                        "Selectividad"=4))

```
## Scenarios

In Table 1 we have ten scenarios to test different option in modeling about main consideration in assessment of krill population.

| Scenario | Description                                      |
|:---------:|:-------------------------------------------------|
|    s01     | Fishery, Predator, Survey, Environmental data agreggate (Whole 48.1) |
|    s1     | Fishery data (Length, Index, Catch) by strata  and Predator and Env data      |
|    s2    | Fishery and Survey (AMLR) data Length, Index, Catch by strata and Predator and Env data |
|    s3     | Same "s2" Without S-R relation         |
|    s4     | Same "s2" Ricker S-R relation estimated          |
|    s5     | Same "s2" BH S-R relation weak (0.9 steepness)     |
|    s6     | Same "s2" BH S-R relation strong (0.6 steepness)     |
|    s7     | Same "s2" BH S-R relation mid-strong (0.65 steepness) estimated     |

## Run Models



```{r eval=FALSE, message=F, include=FALSE}
# Lista de directorios para correro tordos juntos
directorios <- c("s01", 
                 "s1", 
                 "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7")  # Agrega aquí todos los nombres de las carpetas que deseas procesar

# Bucle para ejecutar el código en cada directorio
for (dir in directorios) {
  r4ss::run(
    dir = dir,
    exe = "ss_osx",
    skipfinished = FALSE,
    show_in_console = TRUE
  )
}
#OR with rby separate
#shell(cmd="ss") # run SS to windows
# or 
#system('./ss_osx') # to mac
r4ss::run(
  dir = dir2,
  exe = "ss_osx",
  skipfinished = FALSE, # TRUE will skip running if Report.sso present
  show_in_console = TRUE # change to true to watch the output go past
)
```

Read outputs

```{r message=F, include=FALSE}
#s01
base.model01 <- SS_output(dir=dir01,
                        covar=T,
                        forecast=T)
#s1
base.model1 <- SS_output(dir=dir1,
                        covar=T,
                        forecast=T)
#s2
base.model2 <- SS_output(dir=dir2,
                        covar=T,
                        forecast=T)
#s3
base.model3 <- SS_output(dir=dir3,
                        covar=T,
                        forecast=T)
#s4
base.model4 <- SS_output(dir=dir4,
                        covar=T,
                        forecast=T)
#s5
base.model5 <- SS_output(dir=dir5,
                        covar=T,
                        forecast=T)
#s6
base.model6 <- SS_output(dir=dir6,
                        covar=T,
                        forecast=T)

#s7
base.model7 <- SS_output(dir=dir7,
                        covar=T,
                        forecast=T)
```


```{r eval=FALSE, message=F, include=FALSE}
SS_plots(base.model2, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)
```



```{r fig.height=7}
SSplotData(base.model01, subplot = 1, 
           fleetnames = c("Fishery", "Survey", "Predator"),
           fleetcol = c("blue","green", "red"))

SSplotData(base.model2, 
           subplot = 1,
           pheight = 15)

```

Respecto a los valores y parametros biologicos modelados, los siguientes graficos identifican los estimadores puntuales del recurso

```{r}
SSplotSelex(base.model2,
            subplots = 1)
```


```{r eval=FALSE}
SSplotBiology(base.model2, 
              subplots =2, 
              labels = c("Length (cm)",
                         "Age (yr)",
                         "Maturity", 
                         "Mean weight (kg) in last year",
                          "Spawning output",
                         "Length (cm, beginning of the year)", 
                         "Natural mortality",
                          "Female weight (kg)", 
                         "Female length (cm)", 
                         "Fecundity", 
                         "Default fecundity label",
                          "Year", 
                         "Hermaphroditism transition rate", 
                         "Fraction females by age at equilibrium"),
 )

```

aporte de las cohortes por año para las capturas.
```{r eval=FALSE}
SSplotCohortCatch(base.model2, subplots = 1)
```

\quad

AJuste de tallas por flota
```{r eval=FALSE}
SSplotComps(base.model2, subplots = 1)
```

Otros plots
```{r}
SSplotDynamicB0(base.model2, uncertainty = F)
#SSplotSPR(base.model3)
```


```{r eval=FALSE}
SSplotPars(base.model2)

```

Salida de las biomasas con las dos flotas

```{r}
SSplotTimeseries(base.model01, subplot = 7)
```
Salida de las biomasas con todas las flotas

```{r}
SSplotTimeseries(base.model2, subplot = 7)
```

# RESULTS

## Diagnosis Base Model 

Step to do a good practice in model diagnosis is;

- 1. Convergence. Final convergence criteria is 1.0e-04

- 2. Residual (visual and metrics)

- 3. Retrospective analysis (Mhon Parameter)

- 4. Likelihood profile

all this framework try to follow recommendations of @Carvalho2021b


## Residual

```{r eval=FALSE}
SSplotRunstest(base.model01, 
               subplots = "cpue",
               add=T)
SSplotRunstest(base.model2, 
               subplots = "len",
               add=T)
```


```{r}
SSplotJABBAres(base.model2,
               subplots = "cpue",
               add=T)
SSplotJABBAres(base.model2,
               subplots = "len",
               add=T)
```



## Predator fleet with RW

Random Walk (RW) refers to a mathematical model that describes a stochastic process in which a variable changes randomly over time, without a clear trend or pattern.

Specifically, a random walk can be used as a Bayesian estimation technique to infer the posterior distribution of an unknown parameter. In this approach, it is assumed that the prior distribution of the parameter is a normal distribution with mean zero and a known variance, and that the parameter value at each time step follows a random walk process. Based on the observed data and the prior distribution, the posterior distribution of the parameter can be calculated using Bayesian inference.

Random walk is a useful tool for parameter estimation in dynamic models, as it allows for modeling uncertainty and variability in the parameter's evolution over time. However, it is important to note that the random walk assumes that the changes in the parameter are random and without a clear trend, which may not be appropriate in all cases.

## Retrospective analysis

Los análisis retrospectivo, dan cuenta de diferencias de estimación (sub - sobreestimación) en los patrones entre modelos evaluados. 

```{r eval=FALSE}
retro(dir=dir7, oldsubdir="", 
      newsubdir="Retrospective", 
      years= 0:-5,
      exe="ss_osx",
      extras = "-nox", 
      skipfinished = F)
```


```{r echo=FALSE}
#s01
retroModels01 <- SSgetoutput(dirvec=file.path(dir01,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary01 <- SSsummarize(retroModels01)
# s1
retroModels1 <- SSgetoutput(dirvec=file.path(dir1,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary1 <- SSsummarize(retroModels1)
#s2
retroModels2 <- SSgetoutput(dirvec=file.path(dir2,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary2 <- SSsummarize(retroModels2)
#s3
retroModels3 <- SSgetoutput(dirvec=file.path(dir3,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary3 <- SSsummarize(retroModels3)
#s4
retroModels4 <- SSgetoutput(dirvec=file.path(dir4,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary4 <- SSsummarize(retroModels4)
#s5
retroModels5 <- SSgetoutput(dirvec=file.path(dir5,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary5 <- SSsummarize(retroModels5)
#s6
retroModels6 <- SSgetoutput(dirvec=file.path(dir6,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary6 <- SSsummarize(retroModels6)
#s7
retroModels7 <- SSgetoutput(dirvec=file.path(dir7,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary7 <- SSsummarize(retroModels7)

```


```{r echo FALSE}
#save(retroSummary, retroModels, file="retro5.Rdata")

retro01 <- SSplotRetro(retroSummary01,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)
retro1 <- SSplotRetro(retroSummary1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)
retro2 <- SSplotRetro(retroSummary2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)
retro3 <- SSplotRetro(retroSummary3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)
retro4 <- SSplotRetro(retroSummary4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)
retro5 <- SSplotRetro(retroSummary5,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)

retro6 <- SSplotRetro(retroSummary6,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)


retro7 <- SSplotRetro(retroSummary7,
            add=T,
            forecast = F,
            legend = T,
            verbose=F)


```


```{r echo=FALSE}
ggarrange(retro01,
          retro1,
          retro2,
          retro3,
          retro4,
          retro5,
          retro6,
          retro7, ncol = 4, nrow = 4)
```


## Hindcast Cross-Validation and prediction skill

Implementing the Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis requires the same model outputs generated by `r4ss:SS_doRetro()`. As a robust measure of prediction skill, we implemented the mean absolute scaled error (MASE). In brief, the MASE score scales the mean absolute. Regarding (A MASE score > 1 indicates that the average model forecasts are worse than a random walk. Conversely, a MASE score of 0.5 indicates that the model forecasts twice as
accurately as a naïve baseline prediction; thus, the model has prediction skill.



```{r}
hci = SSplotHCxval(retroSummary2, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```
## Kobe (status)

```{r}
mvln = SSdeltaMVLN(base.model01,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)

mvln = SSdeltaMVLN(base.model2,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)
```


```{r echo=FALSE}
# model01
tablebias01 <- SShcbias(retroSummary01,quant="SSB",verbose=F)
tablebias02 <- SShcbias(retroSummary01,quant="F",verbose=F)

kbl(tablebias01, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias02, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model2
tablebias7 <- SShcbias(retroSummary7,quant="SSB",verbose=F)
tablebias07 <- SShcbias(retroSummary7,quant="F",verbose=F)

kbl(tablebias7, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias7, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")
```



## Verosimilitud

```{r}
like01 <- base.model01$likelihoods_used
like01$model <- rep("s01", nrow(like01))
like01 <- rownames_to_column(like01, var = "Description")
like1 <- base.model1$likelihoods_used
like1$model <- rep("s1", nrow(like1))
like1 <- rownames_to_column(like1, var = "Description")
like2 <- base.model1$likelihoods_used
like2$model <- rep("s2", nrow(like2))
like2 <- rownames_to_column(like2, var = "Description")
like3 <- base.model3$likelihoods_used
like3$model <- rep("s3", nrow(like3))
like3 <- rownames_to_column(like3, var = "Description")
like4 <- base.model4$likelihoods_used
like4$model <- rep("s4", nrow(like4))
like4 <- rownames_to_column(like4, var = "Description")
like5 <- base.model5$likelihoods_used
like5$model <- rep("s5", nrow(like5))
like5 <- rownames_to_column(like5, var = "Description")
like6 <- base.model6$likelihoods_used
like6$model <- rep("s6", nrow(like6))
like6 <- rownames_to_column(like6, var = "Description")
like7 <- base.model7$likelihoods_used
like7$model <- rep("s7", nrow(like7))
like7 <- rownames_to_column(like7, var = "Description")
totalike <- rbind(like01,
                  like1,
                   like2,
                   like3,
                   like4,
                   like5,
                   like6,
                   like7)

```

```{r}
ggplot(totalike)+
  geom_bar( aes(y = reorder(Description, values), x =values),
            stat = "identity", position = "dodge") +
  theme_few() +
  facet_wrap(.~model, 
             ncol=4)+
  labs(y="",
       x="Likelihood")+
  xlim(0, 1000)+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1)) 
```



```{r eval=FALSE, echo = FALSE}
# 1. Identificar el directorio donde se encuentra el modelo base ----
dirname.model.run <- here("s2")
# 2. Crear un nuevo directorio para el "Perfil_Verosimilitud"  
dirname.R0.profile <- here("Ejercicios","Perfil_Verosimilitud")
dir.create(path=dirname.R0.profile, showWarnings = TRUE, recursive = TRUE)
# 3. Crear un subdirectorio llamado "plots_Verosimilitud" ----
plotdir=paste0(dirname.R0.profile, "/plots_Verosimilitud")
dir.create(path=plotdir, showWarnings = TRUE, recursive = TRUE)
# 4. Crear un subdirectorio llamado "simple" ----
reference.dir <- paste0(dirname.R0.profile,'/simple') 
dir.create(path=reference.dir, showWarnings = TRUE, recursive = TRUE)
# 5. Copiar el resultado del modelo base completo en este directorio ----
file.copy(Sys.glob(paste(dirname.model.run, "*.*", sep="/"),
                   dirmark = FALSE),
                    reference.dir)
# 6. Leer la salida del modelo base ----
Base <- SS_output(dir=reference.dir,covar=T)
# 7. Copiar los archivos necesarios de "simple" al directorio "Perfil_Verosimilitud" ----
copy_SS_inputs(dir.old = reference.dir, 
               dir.new =  dirname.R0.profile,
               copy_exe = TRUE,
               verbose = FALSE)
# 8. Leer los archivos del modelo ----
inputs <- r4ss::SS_read(dir = dirname.R0.profile)
# 9. Editar el archivo control la fase de estimación recdev ----
inputs$ctl$recdev_phase <- 1
# 10. Editar el archivo starter para leer los valores de inicio ----
inputs$start$init_values_src <- 0
# 11. Vector de valores para el perfil ----
R0.vec <- seq(15,20,0.5)  
Nprof.R0 <- length(R0.vec)
# 12. Cambiar el nombre del archivo control en el archivo starter.ss ----
inputs$start$ctlfile <- "control_modified.ss" 
# 13. Incluir prior_like para parámetros no estimados ----
inputs$start$prior_like <- 1                                 
# 14. Escribir los modelos modificados ----
r4ss::SS_write(inputs, dir = dirname.R0.profile, overwrite = TRUE)
# 15. Ejecutar la función profile() ----
?SS_profile()
profile <- profile(dir=dirname.R0.profile, # directory
                      exe="ss_osx",
                      oldctlfile ="control.ss",
                      newctlfile="control_modified.ss",
                      string="SR_LN(R0)",
                      profilevec=R0.vec)
# 16. Leer los archivos de salida ----
# (con nombres como Report1.sso, Report2.sso, etc.)
prof.R0.models <- SSgetoutput(dirvec=dirname.R0.profile, 
                              keyvec=1:Nprof.R0, 
                              getcovar = FALSE) 
# 17. Resumir las salidas con la función SSsummarize()  ----
prof.R0.summary <- SSsummarize(prof.R0.models)
# 18. Identificar los componentes de Verosimilitud ----
mainlike_components         <- c('TOTAL',
                                 "Survey", 
                                 'Length_comp',
                                 "Age_comp",
                                 'Size_at_age',
                                 'Recruitment') 
mainlike_components_labels  <- c('Total likelihood',
                                 'Index likelihood',
                                 'Length likelihood',
                                 "Age likelihood",
                                 'Size_at_age likelihood',
                                 'Recruitment likelihood') 
# 19. Funciones para generar plots de perfil de verosimilitud ----
### SSplotProfile() ----
png(file.path(plotdir,"R0_profile_plot.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
SSplotProfile(prof.R0.summary,           # summary object
              profile.string = "R0",     # substring of profile parameter
              profile.label=expression(log(italic(R)[0])), 
              ymax=150,minfraction = 0.001,
              pheight=4.5, 
              print=FALSE, 
              plotdir=plotdir, 
              components = mainlike_components, 
              component.labels = mainlike_components_labels,
              add_cutoff = TRUE,
              cutoff_prob = 0.95)

Baseval <- round(Base$parameters$Value[grep("R0",Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()


### SSplotComparisons() ----
# Comparación de series de tiempo 
labs <- paste("SR_Ln(R0) = ",R0.vec)
labs[which(round(R0.vec,2)==Baseval)] <- paste("SR_Ln(R0) = ",
                                               Baseval,"(Base model)")

SSplotComparisons(prof.R0.summary,
                  legendlabels=labs,
                  pheight=4.5,png=TRUE,
                  plotdir=plotdir,
                  legendloc='bottomleft')

### PinerPlot() ----
#### R0_profile_plot_Length_like ----
png(file.path(plotdir,"R0_profile_plot_Length_like.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, 
          profile.string = "R0", 
          component = "Length_like",
          main = "Changes in length-composition likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95)
Baseval <- round(Base$parameters$Value[grep("SR_LN",
                                      Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,
     label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
#### R0_profile_plot_Survey_like ----
png(file.path(plotdir,"R0_profile_plot_Survey_like.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, 
          profile.string = "R0", 
          component = "Surv_like",
          main = "Changes in Index likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95, legendloc="topleft")
Baseval <- round(Base$parameters$Value[grep("SR_LN",
                                            Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
```

## Outputs Model Base

```{r}
outps2 <- base.model2$timeseries[1:53, 2:8]

addWorksheet(wb, "variable_s2")
writeData(wb, "variable_s2", outps2)

# Guardar el workbook
saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)
```


## Comparision outputs betwwen scenarios

```{r echo=FALSE}
#PLOT labels, name of each model run
legend.labels <- c( "s01",
                  "s1",
                 "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7")

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL,
                       dirvec = c(dir01,
                                  dir1,
                                  dir2,
                                  dir3,
                                  dir4,
                                  dir5,
                                  dir6,
                                  dir7),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)

SSplotComparisons(summaryoutput,
                  legendlabels = c("s01",
                                   "s1",
                                   "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                 labels = c("Year", 
                            "Spawning biomass (t)",
                            "Relative spawning biomass", 
                            "Age-0 recruits (1,000s)",
                            "Recruitment deviations", 
                            "Index", "Log index", 
                            "1 - SPR", 
                            "Density",
                            "Management target", 
                            "Minimum stock size threshold",
                            "Spawning output",
                            "Harvest rate"),
                 plotdir = "~/Figs")

comp <- SSplotComparisons(summaryoutput,
                  legendlabels = c("s01",
                                   "s1",
                                   "s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                 subplots = c(2, 16),
                 plotdir = "~/Figs")
comp
```


```{r}
comtable <- SStableComparisons(summaryoutput,
                   likenames = c("TOTAL", 
                                 "Survey", 
                                 "Length_comp",
                                 "Age_comp", 
                                 "priors",
                                 "Size_at_age"), 
                   names = c("Recr_Virgin",
                             "R0", 
                             "steep",
                             "NatM",
                             "L_at_Amax", 
                             "VonBert_K", 
                             "SSB_Virg", 
                             "Bratio_2017",
                             "SPRratio_2016"),
                   digits = NULL,
                   modelnames = c("s01", "s1","s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                   csv = FALSE,
                   csvdir =~"/DOCAS/SA_Krill",
                   csvfile = "parameter_comparison_table.csv",
                 verbose = TRUE,
                   mcmc = FALSE)
kbl(comtable, booktabs = T,format = "latex",
    caption = "Comparacion likelihood y parámetros s01, s1, s2, s3, s4, s5, s6 y s7")  %>% 
    kable_styling(latex_options = "scale_down")

```


\newpage
# REFERENCES
